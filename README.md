# Video Game History Analysis and RAG Chatbot

## Introduction

This project analyzes 337 video games that are considered some of the best in history, as selected by video game journalists and gaming magazines. It includes two main components:

1. Data visualizations that highlight the most popular genres, gaming platforms, and countries behind these top-rated games using Tableau, Seaborn, and Matpolite.
2. A Retrieval-Augmented Generation (RAG) chatbot built with LangChain and the OpenAI API. This chatbot processes a .txt file containing Wikipedia descriptions of all 337 games and can answer user questions about the content in natural language.

## Data Sources

To support analysis described above, this project used 3 data sources:

| # | Name/short description | Source URL | Type: API/Webpage file | List of fields | Format | Estimated data size, number of data points planned to use |
|---|------------------------|------------|-------------------------|----------------|--------|------------------------------------------------------------|
| 1 | List of video games considered the best (337 games from 1970 ~ 2023) | https://en.wikipedia.org/wiki/List_of_video_games_considered_the_best | Wikipedia HTML table | Game Production Year, Game Title, Genre, Publisher, Original Platforms | HTML text | 337 rows and 5 valid columns |
| 2 | A .txt file contains all 337 games’ Wikipedia descriptions | Generated by codes | Collected from Wikipedia HTML pages and written into .txt | Comprehensive description of each game in great details (game intro, contents, history, popularity, etc.) | .txt | 9MB, contains over 290K English words |
| 3 | A structured CSV file contains cleaned table from source 1 with game publisher country info | Generated by codes | Wikipedia HTML table transformed into CSV | Game Production Year, Game Title, Genre, Publisher, Original Platforms, HQ Location of Publisher | CSV | 337 rows and 6 valid columns |

## Analysis

### Visualizations

The first part of the analysis includes a series of visualizations created using **Matplotlib**, **Seaborn**, and **Tableau**. Since most of these "best games" were primarily nominated by gaming journalists and magazines based in the United States, this project aims to examine the objectivity of the selection process.

By building an **ETL pipeline** to scrape the HTML table containing information on all 337 games and following each publisher's hyperlink to retrieve their country of origin, this project generates a clean and structured CSV file. This data is then used to visualize:
- Number of games by **country**
- Number of games by **genre**
- Number of games by **platform**
- Number of games by **year**

The results can be run in the Jupyter notebook. For more details, read the Analysis section.

### RAG Chatbot

The second part of this project is a Retrieval-Augmented Generation (RAG) chatbot powered by LangChain and the OpenAI API. It processes a .txt file containing Wikipedia descriptions of all 337 games and allows users to ask questions about any game. The chatbot uses vector embeddings and similarity search to identify the most relevant text chunks, then generates human-readable answers powered by GPT-4. This system enables flexible content analysis—for example, if a user wants to know why Minecraft is popular, they can simply ask the chatbot and receive a professional response.

The RAG system designed for this project follows the workflow below:
1. Chunking the .txt file into manageable segments.
2. Extracting keywords from each chunk using KeyBERT.
3. Embedding each chunk and its keywords into vectors.
4. Storing the vectors in a FAISS (Facebook AI Similarity Search) index file.
5. Accepting user questions through a UI.
6. Performing similarity search to retrieve the most relevant chunks and keywords.
7. Sending the retrieved content and the user’s question to GPT-4 via a custom AI prompt.
8. Generating and returning a natural-language answer to the user.

## Summary of the Results

### Visualization Results

To better understand the characteristics of the 337 video games considered the best in history (1970–2023), a series of visualizations were created based on a structured dataset derived from Wikipedia. These visualizations explored trends across genre, geographic distribution of publishers, release periods, and original gaming platforms.

The project visualized key trends among the 337 video games considered the best from 1970 to 2023, revealing several important insights:

<h4 style="color:DarkGreen">Genre Distribution:</h4>  
Action, Platform (game where you control your character jumping from platforms to platforms), Adventure, and Role-Playing were the most frequently occurring genres among top-rated games. These genres consistently dominate due to their strong storytelling, immersive gameplay mechanics, and popularity across both console and PC platforms.

<h4 style="color:DarkOrange">Release Period:</h4>  
The number of acclaimed games increased steadily over the decades, with clear peaks in the late 1990s and early 2010s. These periods coincide with major technological shifts, such as the rise of 3D gaming, online multiplayer, and the growth of indie development. Many famous video games like World of Warcraft were launched during this time.

<h4 style="color:DarkRed">Original Platforms:</h4>  
Early entries were primarily developed for arcade machines and home consoles, especially during the 1980s and 1990s. In more recent years, there has been a strong surge in multi-platform and PC-based releases, driven by digital distribution platforms and broader cross-platform compatibility.

<h4 style="color:MidnightBlue">Company Location:</h4>  
The United States and Japan were the most dominant countries in producing highly acclaimed video games. This reflects the historical and ongoing influence of major companies such as Atari, Nintendo, Sony, Microsoft, Activision, and Rockstar Games, all of which have significantly shaped the global gaming landscape.

However, while the U.S. and Japan clearly lead the industry, it is important to acknowledge potential regional bias in the selection process, as most of the games on the list were chosen by U.S.-based journalists and gaming magazines. The data shows that over half of the games came from U.S. developers, with a substantial portion from Japan. In contrast, only 15 games originated from the United Kingdom, and just one each from countries like Russia and Canada. Notably, there were zero games from China on the list.

To some extent, this outcome highlights the issue of cultural and regional bias in defining what constitutes the “best” video games in history. However, considering that video games originated in the U.S. and were globally popularized through the efforts of Japanese companies like Nintendo, the results still offer a relatively reliable perspective for studying the historical development of the video game industry.

### RAG Chatbot Results

The RAG chatbot developed in this project turns a static text file into an interactive Q&A system that accurately answers open-ended questions about 337 top-rated video games. It uses vector search (FAISS), keyword extraction (KeyBERT), and GPT-4 to generate natural language answers based on relevant content retrieved from Wikipedia descriptions.

For example, when asked:  
**“Introduce the Tetris to me. Is this game popular? If so, why do people like it?”**

The chatbot responded with a well-structured summary, noting that Tetris was created in 1985 by Soviet engineer Alexey Pajitnov, explaining its gameplay, and highlighting its widespread appeal due to simplicity and cultural impact—especially after Nintendo's global promotion.

This shows the chatbot’s ability to understand nuanced questions, retrieve the right content, and deliver clear, factual answers in real time.

While designed for video game analysis, the system is highly flexible. With a different dataset, it can be applied to:

- Customer service, to answer product or support questions
- Education, to help users explore course content interactively
- Internal knowledge tools, for fast document or policy lookup
- Healthcare, to provide medically-informed answers to common patient questions

In short, this RAG chatbot framework can power intelligent, conversational systems across a wide range of industries.


## How to Run

This project includes both visual analysis and a RAG chatbot based on Wikipedia data for 337 highly rated video games. Below are the steps to reproduce the entire pipeline and interact with the chatbot.

### 1. Downloading Code zip

First, go to this repository’s main page -> Click the green "Code" buttom -> Click Download ZIP

### 2. Get your own OpenAI API KEY!

Get your OpenAI API Key at: https://platform.openai.com/api-keys
Then copy your API Key into config.py in downloaded src/ folder

### 3. Create and activate the conda environment

You MUST run this in Conda environment, this means that every time you try to re-run this project after you closed your terminal,
you have to follow the steps below again.

Open your terminal, cd to the downloaded file's directory DSCI510_Final_Project
then run command below in your terminal:

```bash
conda create -n rag_env python=3.9 -y
conda activate rag_env
```

### 4. Upgrade pip and essential build tools

```bash
pip install --upgrade pip setuptools wheel
```

### 5. Install core packages via conda

```bash
conda install -c conda-forge faiss-cpu pyarrow -y
```

### 6. Install Python dependencies

```bash
pip install -r requirements.txt
```

### Then open jupyter notebook, open results.ipynb

Now run the first block in jupyter notebook:

```bash
import sys
import os
sys.path.append(os.path.join(os.getcwd(), 'src'))
!pip install -r requirements.txt
```

You might need to restart the notebook after running this block.

### 1. Data Collection and Cleaning

This step scrapes a Wikipedia table and follows publisher hyperlinks to extract their headquarters. It outputs a cleaned CSV used in the visual analysis.

```python
from get_table_HQ import get_best_games_table
get_best_games_table()
```

### 2. Visualization

This may take somtime to run if this is the first time your computer run things in conda environment
Run the following functions to visualize the cleaned data:

```python
from visualization import (
    plot_games_by_genre,
    count_games_by_country,
    plot_games_by_5year_period,
    plot_games_by_platform
)

plot_games_by_genre()
count_games_by_country()
plot_games_by_5year_period()
plot_games_by_platform()
```

### 3. Text Corpus Scraping (game descriptions)

This step scrapes the Wikipedia pages for each game and saves them into a single `.txt` file.

```python
from hyperlink_scraper import extract_game_links_and_genres, save_to_txt
games = extract_game_links_and_genres(limit=337)
save_to_txt(games, output_file="game.txt")
```

### 4. Chunking, Tagging, and Indexing

Split the text file into chunks, extract tags with KeyBERT, and store everything in an SQLite database and FAISS vector index.

Make sure you already put your OpenAI API key in src/config.py

Then run:

```python
from rag import (
    detect_file_type,
    extract_text,
    split_text_into_chunks,
    generate_chinese_tags,
    create_db,
    file_to_db,
    load_all_from_db,
    build_faiss_index,
    load_vector_storage,
    search_similar_chunks,
    answer_question_with_prompt
)

file_to_db("game.txt")  # This step may take ~30 minutes with KeyBERT

docs = load_all_from_db()
build_faiss_index(docs)
```

### 5. Run the Chatbot (Streamlit UI)

The chatbot uses Streamlit to provide an interactive interface
If you are new to the Streamlit UI, running the code below may prompt you to enter your email or skip it

However, Jupyter Notebook does not allow direct input for this prompt

Therefore, I built the code below to help you automatically skip this step when using Jupyter Notebook

Launch it with:

```python
import subprocess
import os

subprocess.run(
    "echo '' | streamlit run src/app.py",
    shell = True
)

```

You can then ask any question related to the 337 games. The chatbot will retrieve relevant text chunks and generate answers using GPT-4.

If this block doesn’t work for you:

(1) Open your terminal

(2) Move to the src folder where app.py located at

(3) Enter: streamlit run app.py

Then it should be working!

### API Keys Required

- **OpenAI API Key**: Required for embedding and answering via GPT-4.
  - Add your key to `config.py` like this:
    ```python
    OPENAI_API_KEY = "your-api-key-here"
    ```

### Output Files

- `best_video_games.csv`: Cleaned game list with headquarters location
- `game.txt`: Full Wikipedia text of 337 games
- `game.db`: SQLite database storing chunked text and tags
- `faiss_index`: FAISS index file for semantic search

## Thank you very much for testing my project!
## Author: Sim Wang
